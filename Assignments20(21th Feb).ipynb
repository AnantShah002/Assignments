{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcd16541-26ca-40ac-b9d2-6792b0fb614c",
   "metadata": {},
   "source": [
    "### Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "### Ans) \n",
    "Suppose you want some information from a website? Let’s say a paragraph on Donald Trump! What do you do? Well, you can copy and paste the information from Wikipedia to your own file. But what if you want to get large amounts of information from a website as quickly as possible? Such as large amounts of data from a website to train a Machine Learning algorithm? In such a situation, copying and pasting will not work! And that’s when you’ll need to use Web Scraping. \n",
    "\n",
    "1. **Data collection:-** Web scraping is used to collect data from different websites. This data can be used for various purposes such as market research, competitor analysis, and product pricing.\n",
    "\n",
    "2. **Research:-** Web scraping is also used for research purposes. Researchers use web scraping to collect data for academic studies, social media sentiment analysis, and many other research applications.\n",
    "\n",
    "3. **Machine learning:-** Web scraping is used in machine learning to train models with large datasets. For example, a company might use web scraping to collect data on customer reviews, and then use that data to train a machine learning model to predict sentiment.\n",
    "\n",
    "#### Three areas where Web Scraping is used to get data\n",
    "1. **E-Commerce:-** Web Scraping can be used to periodically extract data of products from various e-commerce websites like Amazon, eBay, Google Shopping etc. Product details like price, description, images, reviews, rating etc. can be easily extracted using a web scraping software.\n",
    "2. **Sports Betting Odds Analysis:-** Web scraping is used to collect betting odds values by various bookmakers from sports betting websites like OddsPortal, BetExplorer, FlashScore etc.\n",
    "3. **Lead Generation for Marketing:-** A web scraping software can be used to generate leads for marketing. Email and Phone lists for cold outreach can be built by scraping the data from relevant websites. For example, business contact details like phone number and email address can be scraped from yellow pages websites or from Google Maps business listings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd76ffe-5df4-4a87-b143-ace712899ddc",
   "metadata": {},
   "source": [
    "### Q2. What are the different methods used for Web Scraping?\n",
    "### Ans)\n",
    "Here are a few techniques commonly used to scrape data from websites. In general, all web scraping techniques retrieve content from websites, process it using a scraping engine, and generate one or more data files with the extracted content.\n",
    "\n",
    "> HTML Parsing\n",
    "\n",
    "HTML parsing involves the use of JavaScript to target a linear or nested HTML page. It is a powerful and fast method for extracting text and links (e.g. a nested link or email address), scraping screens and pulling resources.\n",
    "\n",
    "> DOM Parsing\n",
    "\n",
    "The Document Object Model (DOM) defines the structure, style and content of an XML file. Scrapers typically use a DOM parser to view the structure of web pages in depth. DOM parsers can be used to access the nodes that contain information and scrape the web page with tools like XPath. For dynamically generated content, scrapers can embed web browsers like Firefox and Internet Explorer to extract whole web pages (or parts of them).\n",
    "\n",
    "> Vertical Aggregation\n",
    "\n",
    "Companies that use extensive computing power can create vertical aggregation platforms to target particular verticals. These are data harvesting platforms that can be run on the cloud and are used to automatically generate and monitor bots for certain verticals with minimal human intervention. Bots are generated according to the information required to each vertical, and their efficiency is determined by the quality of data they extract.\n",
    "\n",
    "> XPath\n",
    "\n",
    "XPath is short for XML Path Language, which is a query language for XML documents. XML documents have tree-like structures, so scrapers can use XPath to navigate through them by selecting nodes according to various parameters. A scraper may combine DOM parsing with XPath to extract whole web pages and publish them on a destination site.\n",
    "\n",
    "> Google Sheets\n",
    "\n",
    "Google Sheets is a popular tool for data scraping. Scarpers can use the IMPORTXML function in Sheets to scrape from a website, which is useful if they want to extract a specific pattern or data from the website. This command also makes it possible to check if a website can be scraped or is protected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642d921e-267b-417c-99c1-2f2f6a589040",
   "metadata": {},
   "source": [
    "### Q3. What is Beautiful Soup? Why is it used?\n",
    "### Ans)\n",
    "Beautiful Soup is a Python package for parsing HTML and XML documents (including having malformed markup, non-closed tags, so named after tag soup). It creates a parse tree for parsed pages that can be used to extract data from HTML, which is useful for web scraping.\n",
    "\n",
    "1. **Parsing HTML and XML documents:-** Beautiful Soup can parse both HTML and XML documents, making it a versatile tool for web scraping.\n",
    "\n",
    "2. **Extraction of data:-** Beautiful Soup provides a set of functions that allow developers to extract data from web pages based on the page structure, element attributes, and other criteria.\n",
    "\n",
    "3. **Navigation:-** Beautiful Soup provides a navigable tree-like representation of the HTML or XML document, allowing developers to easily navigate through the document structure and extract data from specific elements.\n",
    "\n",
    "4. **Compatibility:-** with popular Python libraries: Beautiful Soup is compatible with popular Python libraries such as Requests and Pandas, making it easy to integrate web scraping into existing Python workflows.\n",
    "\n",
    "5. **Flexibility:-** Beautiful Soup is a flexible tool that can be used for a wide range of web scraping tasks, from simple data extraction to complex web crawling and scraping of dynamic websites."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19889b32-d751-4c76-8c37-989ba1f85c7d",
   "metadata": {},
   "source": [
    "### Q4. Why is flask used in this Web Scraping project?\n",
    "### Ans) \n",
    "Flask is a lightweight framework to build websites. We’ll use this to parse our collected data and display it as HTML in a new HTML file. The requests module allows us to send http requests to the website we want to scrape.\n",
    "1. **Building a web interface:-** Flask can be used to create a simple web interface for the web scraping project, allowing users to enter URLs or search terms, and displaying the results of the web scraping.\n",
    "\n",
    "2. **Running a web server:-** Flask can be used to run a web server that serves the web scraping application, making it accessible to users over the internet.\n",
    "\n",
    "3. **Handling HTTP requests:-** Flask provides tools for handling HTTP requests, such as GET and POST requests, which are used in web scraping to retrieve data from web pages.\n",
    "\n",
    "4. **Managing session data:-** Flask can manage session data, allowing users to save and retrieve information between requests. This can be useful for web scraping projects where users need to store data between different scraping sessions.\n",
    "\n",
    "5. **Integration with other Python libraries:-** Flask can be easily integrated with other Python libraries, including web scraping libraries like Beautiful Soup and Requests, making it a powerful tool for building web scraping applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac6bbf5-f444-492e-8d77-8eb587507d59",
   "metadata": {},
   "source": [
    "### Q5. Write the names of AWS services used in this project. Also, explain the use of each service.### \n",
    "# Ans)\n",
    "* **AWS Lambda:-** AWS Lambda is a serverless computing service that can be used to run web scraping scripts in response to events, \n",
    "            such as file uploads or HTTP requests.\n",
    "\n",
    "* **Amazon API Gateway:-** Amazon API Gateway can be used to create APIs for accessing scraped data or triggering web scraping scripts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
